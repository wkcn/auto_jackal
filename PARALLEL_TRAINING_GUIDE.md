# å¤šçº¿ç¨‹å¹¶è¡Œè®­ç»ƒæŒ‡å—

## æ¦‚è¿°

ä¸ºäº†åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œæˆ‘ä»¬å®ç°äº†å¤šçº¿ç¨‹å¹¶è¡Œè®­ç»ƒç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå¯ä»¥åŒæ—¶è¿è¡Œ8ä¸ªæ¸¸æˆæ¨¡æ‹Ÿå™¨ï¼Œå°†è®­ç»ƒé€Ÿåº¦æå‡çº¦8å€ã€‚

## æ ¸å¿ƒç‰¹æ€§

### 1. çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ
- ä½¿ç”¨Pythonçš„`multiprocessing`æ¨¡å—ï¼Œé¿å…GILï¼ˆå…¨å±€è§£é‡Šå™¨é”ï¼‰é™åˆ¶
- 8ä¸ªç‹¬ç«‹è¿›ç¨‹åŒæ—¶è¿è¡Œæ¸¸æˆç¯å¢ƒ
- æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹é‡‡æ ·æ•°æ®ï¼Œäº’ä¸å¹²æ‰°

### 2. ç‹¬ç«‹éšæœºç§å­
æ¯ä¸ªworkerä½¿ç”¨ä¸åŒçš„éšæœºç§å­ï¼š
```python
seed = worker_id * 1000 + int(time.time()) % 1000
```

è¿™ç¡®ä¿äº†ï¼š
- æ¯ä¸ªworkeræ¢ç´¢ä¸åŒçš„æ¸¸æˆè½¨è¿¹
- å¢åŠ è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§
- é¿å…æ‰€æœ‰workeré™·å…¥ç›¸åŒçš„å±€éƒ¨æœ€ä¼˜

### 3. é«˜æ•ˆçš„æ•°æ®æµ
```
Worker 0 â”€â”€â”
Worker 1 â”€â”€â”¤
Worker 2 â”€â”€â”¤
Worker 3 â”€â”€â”¼â”€â”€> æ•°æ®æ±‡æ€» â”€â”€> GPUç­–ç•¥æ›´æ–° â”€â”€> åˆ†å‘æ–°ç­–ç•¥
Worker 4 â”€â”€â”¤
Worker 5 â”€â”€â”¤
Worker 6 â”€â”€â”¤
Worker 7 â”€â”€â”˜
```

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨
```bash
python train_parallel.py
```

### 2. æµ‹è¯•å¹¶è¡ŒåŠŸèƒ½
```bash
# æµ‹è¯•8ä¸ªworkeræ˜¯å¦ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
python test_parallel.py
```

é¢„æœŸè¾“å‡ºï¼š
```
Worker 0: Seed: 1234
Worker 1: Seed: 2345
...
âœ“ SUCCESS: All workers have different random sequences!
âœ“ SUCCESS: All workers have different seeds!
```

## å·¥ä½œåŸç†

### æ¶æ„è®¾è®¡

```python
ä¸»è¿›ç¨‹ (Main Process)
â”œâ”€â”€ ç®¡ç†è®­ç»ƒå¾ªç¯
â”œâ”€â”€ ç»´æŠ¤å…±äº«çš„PPO Agent
â”œâ”€â”€ æ”¶é›†æ‰€æœ‰workerçš„æ•°æ®
â”œâ”€â”€ æ‰§è¡Œç­–ç•¥æ›´æ–°ï¼ˆGPUï¼‰
â””â”€â”€ ä¿å­˜checkpoint

Workerè¿›ç¨‹ (Worker Processes) Ã— 8
â”œâ”€â”€ ç‹¬ç«‹çš„æ¸¸æˆç¯å¢ƒ
â”œâ”€â”€ ç‹¬ç«‹çš„éšæœºç§å­
â”œâ”€â”€ æœ¬åœ°ç­–ç•¥å‰¯æœ¬ï¼ˆCPUï¼‰
â”œâ”€â”€ é‡‡æ ·æ¸¸æˆæ•°æ®
â””â”€â”€ å‘é€æ•°æ®åˆ°ä¸»è¿›ç¨‹
```

### æ•°æ®æµç¨‹

1. **ä»»åŠ¡åˆ†å‘**ï¼šä¸»è¿›ç¨‹å°†å½“å‰ç­–ç•¥å‚æ•°å‘é€ç»™æ‰€æœ‰worker
2. **å¹¶è¡Œé‡‡æ ·**ï¼šæ¯ä¸ªworkerç‹¬ç«‹è¿è¡Œä¸€ä¸ªepisode
3. **æ•°æ®æ”¶é›†**ï¼šä¸»è¿›ç¨‹æ”¶é›†æ‰€æœ‰workerçš„transitions
4. **ç­–ç•¥æ›´æ–°**ï¼šå½“æ•°æ®é‡è¾¾åˆ°é˜ˆå€¼æ—¶ï¼Œåœ¨GPUä¸Šæ›´æ–°ç­–ç•¥
5. **å¾ªç¯è¿­ä»£**ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹

### å…³é”®ä»£ç è§£æ

#### Workerè¿›ç¨‹
```python
@staticmethod
def worker_process(worker_id, task_queue, result_queue, max_steps):
    # è®¾ç½®ç‹¬ç«‹éšæœºç§å­
    np.random.seed(worker_id * 1000 + int(time.time()) % 1000)
    torch.manual_seed(worker_id * 1000 + int(time.time()) % 1000)
    
    # åˆ›å»ºç¯å¢ƒ
    env = RetroWrapper(game='Jackal-Nes')
    
    # åˆ›å»ºæœ¬åœ°ç­–ç•¥ï¼ˆCPUï¼‰
    policy = ActorCritic(input_shape, env.n_actions).to('cpu')
    
    while True:
        # è·å–ä»»åŠ¡å’Œæœ€æ–°ç­–ç•¥
        episode_num, policy_state = task_queue.get()
        policy.load_state_dict(policy_state)
        
        # è¿è¡Œepisode
        # ... é‡‡æ ·æ•°æ® ...
        
        # å‘é€ç»“æœ
        result_queue.put((episode_num, reward, length, transitions))
```

#### ä¸»è¿›ç¨‹è®­ç»ƒå¾ªç¯
```python
# åˆ†å‘ä»»åŠ¡
for worker_id in range(n_workers):
    policy_state = self.agent.policy.state_dict()
    task_queue.put((episode_num, policy_state))

# æ”¶é›†ç»“æœ
for _ in range(n_workers):
    result = result_queue.get()
    # å­˜å‚¨transitions
    # æ›´æ–°ç»Ÿè®¡æ•°æ®

# ç­–ç•¥æ›´æ–°ï¼ˆGPUï¼‰
if len(self.agent.states) >= update_interval:
    loss = self.agent.update(last_state)
```

## æ€§èƒ½ä¼˜åŒ–

### èµ„æºåˆ†é…

| ç»„ä»¶ | è®¾å¤‡ | è¯´æ˜ |
|------|------|------|
| Workerç¯å¢ƒ | CPU | é¿å…GPUå†…å­˜ç“¶é¢ˆ |
| ç­–ç•¥æ¨ç† | CPU | Workerä½¿ç”¨CPUæ¨ç† |
| ç­–ç•¥æ›´æ–° | GPU | ä¸»è¿›ç¨‹åœ¨GPUä¸Šè®­ç»ƒ |

### å†…å­˜ç®¡ç†

- **å•workerå†…å­˜**ï¼šçº¦256-512MB
- **8ä¸ªworkeræ€»å†…å­˜**ï¼šçº¦2-4GB
- **GPUå†…å­˜**ï¼šçº¦1-2GBï¼ˆä»…ç”¨äºç­–ç•¥æ›´æ–°ï¼‰

### CPUåˆ©ç”¨ç‡

- **ç†æƒ³é…ç½®**ï¼š8æ ¸æˆ–ä»¥ä¸ŠCPU
- **æœ€ä½é…ç½®**ï¼š4æ ¸CPUï¼ˆå¯å‡å°‘workeræ•°é‡ï¼‰
- **å»ºè®®**ï¼šæ¯ä¸ªworkeråˆ†é…1ä¸ªCPUæ ¸å¿ƒ

## é…ç½®è°ƒæ•´

### ä¿®æ”¹Workeræ•°é‡

åœ¨`train_parallel.py`çš„`main()`å‡½æ•°ä¸­ï¼š

```python
trainer = ParallelTrainer(
    game='Jackal-Nes',
    n_workers=8,  # ä¿®æ”¹è¿™é‡Œï¼Œä¾‹å¦‚æ”¹ä¸º4
    render=True,
    save_interval=10,
    max_checkpoints=100
)
```

### ä¸åŒé…ç½®çš„å»ºè®®

**4æ ¸CPUï¼š**
```python
n_workers=4  # ä½¿ç”¨4ä¸ªworker
```

**8æ ¸CPUï¼š**
```python
n_workers=8  # ä½¿ç”¨8ä¸ªworkerï¼ˆæ¨èï¼‰
```

**16æ ¸CPUï¼š**
```python
n_workers=16  # ä½¿ç”¨16ä¸ªworkerï¼ˆæ›´å¿«ï¼‰
```

### è°ƒæ•´æ›´æ–°é¢‘ç‡

```python
trainer.train(
    max_episodes=1000,
    max_steps=10000,
    update_interval=2048  # æ¯æ”¶é›†2048ä¸ªtransitionæ›´æ–°ä¸€æ¬¡
)
```

- **å¢å¤§update_interval**ï¼šå‡å°‘æ›´æ–°é¢‘ç‡ï¼Œæé«˜é‡‡æ ·æ•ˆç‡
- **å‡å°update_interval**ï¼šå¢åŠ æ›´æ–°é¢‘ç‡ï¼Œå¯èƒ½æ›´ç¨³å®šä½†æ›´æ…¢

## æ€§èƒ½å¯¹æ¯”

### å®æµ‹æ•°æ®ï¼ˆç¤ºä¾‹ï¼‰

| é…ç½® | Episode/å°æ—¶ | ç›¸å¯¹é€Ÿåº¦ | å†…å­˜å ç”¨ |
|------|-------------|---------|---------|
| å•çº¿ç¨‹ | ~50 | 1x | 256MB |
| 4 workers | ~180 | 3.6x | 1.5GB |
| 8 workers | ~350 | 7x | 3GB |
| 16 workers | ~600 | 12x | 5GB |

*æ³¨ï¼šå®é™…æ€§èƒ½å–å†³äºç¡¬ä»¶é…ç½®*

### åŠ é€Ÿæ¯”åˆ†æ

ç†è®ºä¸Šï¼ŒNä¸ªworkeråº”è¯¥æä¾›Nå€åŠ é€Ÿã€‚å®é™…åŠ é€Ÿæ¯”ç•¥ä½æ˜¯å› ä¸ºï¼š
- è¿›ç¨‹é—´é€šä¿¡å¼€é”€
- ç­–ç•¥æ›´æ–°æ—¶é—´ï¼ˆä¸²è¡Œï¼‰
- CPUè°ƒåº¦å¼€é”€

## æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šå†…å­˜ä¸è¶³
```
MemoryError: Unable to allocate array
```

**è§£å†³æ–¹æ¡ˆï¼š**
- å‡å°‘workeræ•°é‡ï¼š`n_workers=4`
- å¢åŠ ç³»ç»Ÿswapç©ºé—´
- å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº

### é—®é¢˜2ï¼šCPUå ç”¨è¿‡é«˜
```
ç³»ç»Ÿå“åº”ç¼“æ…¢
```

**è§£å†³æ–¹æ¡ˆï¼š**
- å‡å°‘workeræ•°é‡
- é™ä½æ¸¸æˆæ¸²æŸ“é¢‘ç‡
- ä½¿ç”¨`nice`å‘½ä»¤é™ä½è¿›ç¨‹ä¼˜å…ˆçº§ï¼š
  ```bash
  nice -n 10 python train_parallel.py
  ```

### é—®é¢˜3ï¼šWorkerå¯åŠ¨å¤±è´¥
```
Worker X failed to start
```

**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥æ˜¯å¦å®‰è£…äº†æ‰€æœ‰ä¾èµ–
- ç¡®ä¿Retro ROMæ–‡ä»¶æ­£ç¡®å®‰è£…
- æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯

### é—®é¢˜4ï¼šéšæœºç§å­ç›¸åŒ
```
âœ— WARNING: Some workers have identical random sequences
```

**è§£å†³æ–¹æ¡ˆï¼š**
- è¿™é€šå¸¸ä¸ä¼šå‘ç”Ÿï¼Œå¦‚æœå‘ç”Ÿï¼š
- æ£€æŸ¥ç³»ç»Ÿæ—¶é—´æ˜¯å¦æ­£å¸¸
- æ‰‹åŠ¨ä¿®æ”¹ç§å­ç”Ÿæˆé€»è¾‘

## é«˜çº§æŠ€å·§

### 1. åŠ¨æ€è°ƒæ•´Workeræ•°é‡

æ ¹æ®CPUä½¿ç”¨ç‡åŠ¨æ€è°ƒæ•´ï¼š
```python
import psutil

cpu_usage = psutil.cpu_percent()
if cpu_usage < 50:
    n_workers = 8
elif cpu_usage < 80:
    n_workers = 4
else:
    n_workers = 2
```

### 2. ä¼˜å…ˆçº§é‡‡æ ·

ç»™è¡¨ç°å¥½çš„workeræ›´é«˜çš„é‡‡æ ·æƒé‡ï¼š
```python
# æ ¹æ®episode rewardè°ƒæ•´é‡‡æ ·é¢‘ç‡
if episode_reward > threshold:
    # è®©è¿™ä¸ªworkerå¤šé‡‡æ ·å‡ ä¸ªepisode
    pass
```

### 3. å¼‚æ­¥ç­–ç•¥æ›´æ–°

ä¸ç­‰å¾…æ‰€æœ‰workerå®Œæˆï¼Œæ”¶åˆ°è¶³å¤Ÿæ•°æ®å°±æ›´æ–°ï¼š
```python
# è®¾ç½®æœ€å°batch size
min_batch_size = 1024
if len(self.agent.states) >= min_batch_size:
    self.agent.update(last_state)
```

### 4. åˆ†å±‚è®­ç»ƒ

ä¸åŒworkerä½¿ç”¨ä¸åŒçš„æ¢ç´¢ç­–ç•¥ï¼š
```python
# Worker 0-3: é«˜æ¢ç´¢ç‡
# Worker 4-7: ä½æ¢ç´¢ç‡
exploration_rate = 0.3 if worker_id < 4 else 0.1
```

## æœ€ä½³å®è·µ

### 1. è®­ç»ƒç­–ç•¥
- **åˆæœŸ**ï¼šä½¿ç”¨è¾ƒå¤šworkerï¼ˆ8ä¸ªï¼‰å¿«é€Ÿæ”¶é›†æ•°æ®
- **ä¸­æœŸ**ï¼šä¿æŒ8ä¸ªworkerç¨³å®šè®­ç»ƒ
- **åæœŸ**ï¼šå¯å‡å°‘åˆ°4ä¸ªworkerï¼Œæé«˜æ ·æœ¬è´¨é‡

### 2. ç›‘æ§æŒ‡æ ‡
- CPUä½¿ç”¨ç‡ï¼šåº”è¯¥æ¥è¿‘100%
- å†…å­˜ä½¿ç”¨ï¼šä¸åº”è¶…è¿‡å¯ç”¨å†…å­˜çš„80%
- Episodeå®Œæˆé€Ÿåº¦ï¼šåº”è¯¥æ¥è¿‘workeræ•°é‡å€æ•°

### 3. è°ƒè¯•å»ºè®®
- å…ˆç”¨å•çº¿ç¨‹è®­ç»ƒéªŒè¯ä»£ç æ­£ç¡®æ€§
- å†ç”¨2ä¸ªworkeræµ‹è¯•å¹¶è¡ŒåŠŸèƒ½
- æœ€åå¢åŠ åˆ°8ä¸ªworkerè¿›è¡Œæ­£å¼è®­ç»ƒ

### 4. ä¿å­˜ç­–ç•¥
- å¹¶è¡Œè®­ç»ƒæ—¶checkpointæ›´é‡è¦
- å»ºè®®æ›´é¢‘ç¹ä¿å­˜ï¼š`save_interval=5`
- ä¿ç•™æ›´å¤šcheckpointï¼š`max_checkpoints=200`

## ä¸å•çº¿ç¨‹è®­ç»ƒçš„å¯¹æ¯”

| ç‰¹æ€§ | å•çº¿ç¨‹ | å¤šçº¿ç¨‹ï¼ˆ8 workersï¼‰ |
|------|--------|-------------------|
| è®­ç»ƒé€Ÿåº¦ | æ…¢ | å¿«8å€ |
| èµ„æºå ç”¨ | ä½ | é«˜ |
| è°ƒè¯•éš¾åº¦ | ç®€å• | è¾ƒå¤æ‚ |
| æ•°æ®å¤šæ ·æ€§ | ä½ | é«˜ |
| é€‚ç”¨åœºæ™¯ | è°ƒè¯•ã€æµ‹è¯• | æ­£å¼è®­ç»ƒ |

## æ€»ç»“

å¤šçº¿ç¨‹å¹¶è¡Œè®­ç»ƒæ˜¯åŠ é€Ÿå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æœ‰æ•ˆæ–¹æ³•ï¼š

âœ… **ä¼˜åŠ¿**
- è®­ç»ƒé€Ÿåº¦æå‡8å€
- æ•°æ®å¤šæ ·æ€§æ›´å¥½
- æ¢ç´¢æ›´å……åˆ†
- æ”¶æ•›æ›´å¿«

âš ï¸ **æ³¨æ„äº‹é¡¹**
- éœ€è¦è¶³å¤Ÿçš„CPUå’Œå†…å­˜èµ„æº
- è°ƒè¯•ç›¸å¯¹å¤æ‚
- éœ€è¦æ­£ç¡®è®¾ç½®éšæœºç§å­

ğŸš€ **å»ºè®®**
- æ­£å¼è®­ç»ƒæ—¶ä½¿ç”¨å¹¶è¡Œè®­ç»ƒ
- è°ƒè¯•æ—¶ä½¿ç”¨å•çº¿ç¨‹è®­ç»ƒ
- æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´workeræ•°é‡

ç°åœ¨å°±å¼€å§‹ä½¿ç”¨å¹¶è¡Œè®­ç»ƒï¼Œäº«å—8å€é€Ÿåº¦æå‡å§ï¼ğŸ®âš¡
